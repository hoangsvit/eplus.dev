---
title: "Build an application to send Chat Prompts using the Gemini model - bb-ide-genai-003"
seoTitle: "Build an application to send Chat Prompts using the Gemini model - bb-"
seoDescription: "Generative AI on Vertex AI (also known as genAI or gen AI) gives you access to Google's large generative AI models so you can test, tune, and deploy them fo"
datePublished: Mon Apr 14 2025 09:58:16 GMT+0000 (Coordinated Universal Time)
cuid: cm9gwhzie002u08jo337cczog
slug: build-an-application-to-send-chat-prompts-using-the-gemini-model-bb-ide-genai-003
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1744624665588/ff7f87de-824e-4513-8fc7-2d7f0df38405.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1744624683104/f952ce30-fa9c-4c7f-b1d0-3d32646c7f01.png
tags: build-an-application-to-send-chat-prompts-using-the-gemini-model-bb-ide-genai-003, build-an-application-to-send-chat-prompts-using-the-gemini-model, bb-ide-genai-003

---

## Overview

* Labs are timed and cannot be paused. The timer starts when you click **Start Lab**.
    
* The included cloud terminal is preconfigured with the gcloud SDK.
    
* Use the terminal to execute commands and then click **Check my progress** to verify your work.
    

## Objective

Generative AI on Vertex AI (also known as genAI or gen AI) gives you access to Google's large generative AI models so you can test, tune, and deploy them for use in your AI-powered applications. In this lab, you will:

* **Connect to Vertex AI (Google Cloud AI platform):** Learn how to establish a connection to Google's AI services using the Vertex AI SDK.
    
* **Load a pre-trained generative AI model -Gemini:** Discover how to use a powerful, pre-trained AI model without building one from scratch.
    
* **Send text to the AI model:** Understand how to provide input for the AI to process.
    
* **Extract chat responses from the AI:** Learn how to handle and interpret the chat responses generated by the AI model.
    
* **Understand the basics of building AI applications:** Gain insights into the core concepts of integrating AI into software projects.
    

## Working with Generative AI

After starting the lab, you will get a split pane view consisting of the Code Editor on the left side and the lab instructions on the right side. Follow these steps to interact with the Generative AI APIs using Vertex AI Python SDK.

### Chat responses without using stream:

Streaming involves receiving responses to prompts as they are generated. That is, as soon as the model generates output tokens, the output tokens are sent. A non-streaming response to prompts is sent only after all of the output tokens are generated.

First we'll explore the chat responses without using stream.

Create a new file to get the chat responses without using stream:

1. Click **File &gt; New File** to open a new file within the Code Editor.
    
2. Copy and paste the provided code snippet into your file.
    

```python
from google import genai
from google.genai.types import HttpOptions, ModelContent, Part, UserContent

import logging
from google.cloud import logging as gcp_logging

# ------  Below cloud logging code is for Qwiklab's internal use, do not edit/remove it. --------
# Initialize GCP logging
gcp_logging_client = gcp_logging.Client()
gcp_logging_client.setup_logging()

client = genai.Client(
    vertexai=True,
    project='qwiklabs-gcp-03-b2c7c7cbe5b0',
    location='europe-west1',
    http_options=HttpOptions(api_version="v1")
)
chat = client.chats.create(
    model="gemini-2.0-flash-001",
    history=[
        UserContent(parts=[Part(text="Hello")]),
        ModelContent(
            parts=[Part(text="Great to meet you. What would you like to know?")],
        ),
    ],
)
response = chat.send_message("What are all the colors in a rainbow?")
print(response.text)

response = chat.send_message("Why does it appear when it rains?")
print(response.text)
```

3. Click **File &gt; Save**, enter [`SendChatwithoutStream.py`](http://SendChatwithoutStream.py) for the Name field and click **Save**.
    
4. Execute the Python file by clicking the triangle icon on the top-right corner of Code Editor or by running the below command inside the terminal within the Code Editor pane to view the output.
    

```apache
/usr/bin/python3 /SendChatwithoutStream.py
```

### Code Explanation

* The code snippet is loading a pre-trained AI model called Gemini (gemini-2.0-flash-001) on Vertex AI.
    
* The code calls the `send_message` method of the loaded Gemini model.
    
* The code uses Gemini's ability to chat. It uses the text provided in the prompt to chat.
    

### Chat responses with using stream:

Now we'll explore the chat responses using stream.

Create a new file to get the chat responses with using stream:

5. Click **File &gt; New File** to open a new file within the Code Editor.
    
6. Copy and paste the provided code snippet into your file.
    

```python
from google import genai
from google.genai.types import HttpOptions

import logging
from google.cloud import logging as gcp_logging

# ------  Below cloud logging code is for Qwiklab's internal use, do not edit/remove it. --------
# Initialize GCP logging
gcp_logging_client = gcp_logging.Client()
gcp_logging_client.setup_logging()

client = genai.Client(
    vertexai=True,
    project='qwiklabs-gcp-03-b2c7c7cbe5b0',
    location='europe-west1',
    http_options=HttpOptions(api_version="v1")
)
chat = client.chats.create(model="gemini-2.0-flash-001")
response_text = ""

for chunk in chat.send_message_stream("What are all the colors in a rainbow?"):
    print(chunk.text, end="")
    response_text += chunk.text
```

7. Click **File &gt; Save**, enter [`SendChatwithStream.py`](http://SendChatwithStream.py) for the Name field and click **Save**.
    
8. Execute the Python file by clicking the triangle icon on the top-right corner of Code Editor or by running the below command inside the terminal within the Code Editor pane to view the output.
    

```apache
/usr/bin/python3 /SendChatwithStream.py
```

### Code Explanation

* The code snippet is loading a pre-trained AI model called Gemini (**gemini-2.0-flash-001**) on Vertex AI.
    
* The code calls the `send_message_stream` method of the loaded Gemini model.
    
* The code uses Gemini's ability to understand prompts and have a stateful chat conversation.
    

**Try it yourself!** Experiment with different prompts to explore Gemini's capabilities.

Click **Check my progress** to verify the objective.

Send the text prompt requests to Gen AI and receive a chat response

**Check my progress**

---

## Solution of Lab

%[https://youtu.be/kGWgH0mTn-c] 

```apache
curl -LO https://raw.githubusercontent.com/Itsabhishek7py/GoogleCloudSkillsboost/refs/heads/main/Build%20an%20application%20to%20send%20Chat%20Prompts%20using%20the%20Gemini%20model/abhishek.sh
source abhishek.sh
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1744624614319/a88f8bce-69a0-4da3-9a43-fadf1d58598e.png align="center")