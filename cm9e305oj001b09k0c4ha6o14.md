---
title: "Consuming Customer Specific Datasets from Data Sharing Partners using BigQuery - GSP1043"
seoTitle: "Consuming Customer Specific Datasets from Data Sharing Partners using"
seoDescription: "A common scenario is where a Google Cloud Data Sharing Partner has proprietary datasets that customers can use for their analytics use cases. Customers need"
datePublished: Sat Apr 12 2025 10:37:03 GMT+0000 (Coordinated Universal Time)
cuid: cm9e305oj001b09k0c4ha6o14
slug: consuming-customer-specific-datasets-from-data-sharing-partners-using-bigquery-gsp1043
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1744453303292/288c800a-e445-4ff8-a02f-cec70749a02d.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1744454210889/5c88d6cb-df47-425b-9002-099eafd15c1e.png
tags: consuming-customer-specific-datasets-from-data-sharing-partners-using-bigquery-gsp1043, consuming-customer-specific-datasets-from-data-sharing-partners-using-bigquery, gsp1043

---

## Overview

A common scenario is where a Google Cloud Data Sharing Partner has proprietary datasets that customers can use for their analytics use cases. Customers need to subscribe to this data, query it within their own platform, then augment it with their own datasets and use their visualization tools for their customer facing dashboards. This enables Data Sharing Partners to simplify and accelerate how they build and deliver value from data-driven solutions.

![overview diagram](https://cdn.qwiklabs.com/I0dXN%2FnFXGEMlrAQwEOky4LHqxfkTR50FvHFHv2FmVc%3D align="left")

Through integration with Google Cloud IAM, you can set permissions on BigQuery objects to enable access by users inside or outside of organizations. In this lab, you will learn how Data Sharing Partners create Data Twins for customers either on Google Cloud or a different cloud service provider. For the purposes of this lab, the customer is on Google Cloud in a different project.

In this lab, you will wear two hats and be provided with three Google Cloud projects. In the first project, you are taking on the role of a Data Sharing Partner sharing a dataset generated by the partner's hosted solution using a Data Publishing project. In the second project, you will assume the role of a Data Sharing Partner who will share the source dataset in partner project as an authorized view in the Data Publishing project. In the third project, you will assume the role of a customer who will access the authorized view into their project as a Data Twin and join the data with their solution dataset to create enriched datasets.

## Objectives

In this lab, you will:

* Create an authorized view for a Data Sharing Partner Dataset in different projects
    
* Secure access to the authorized view for a specific customer
    
* Use a customer generated dataset to join with the Data Sharing Partner dataset to create new insights
    

## Setup and Requirements

### Before you click the Start Lab button

Read these instructions. Labs are timed and you cannot pause them. The timer, which starts when you click **Start Lab**, shows how long Google Cloud resources are made available to you.

This hands-on lab lets you do the lab activities in a real cloud environment, not in a simulation or demo environment. It does so by giving you new, temporary credentials you use to sign in and access Google Cloud for the duration of the lab.

To complete this lab, you need:

* Access to a standard internet browser (Chrome browser recommended).
    

**Note:** Use an Incognito (recommended) or private browser window to run this lab. This prevents conflicts between your personal account and the student account, which may cause extra charges incurred to your personal account.

* Time to complete the labâ€”remember, once you start, you cannot pause a lab.
    

**Note:** Use only the student account for this lab. If you use a different Google Cloud account, you may incur charges to that account.

### How to start your lab and sign in to the Google Cloud console

1. Click the **Start Lab** button. If you need to pay for the lab, a dialog opens for you to select your payment method. On the left is the Lab Details pane with the following:
    
    * The Open Google Cloud console button
        
    * Time remaining
        
    * The temporary credentials that you must use for this lab
        
    * Other information, if needed, to step through this lab
        
2. Click **Open Google Cloud console** (or right-click and select **Open Link in Incognito Window** if you are running the Chrome browser).
    
    The lab spins up resources, and then opens another tab that shows the Sign in page.
    
    ***Tip:*** Arrange the tabs in separate windows, side-by-side.
    
    **Note:** If you see the **Choose an account** dialog, click **Use Another Account**.
    
3. If necessary, copy the **Username** below and paste it into the **Sign in** dialog.
    
    ```apache
    "Username"
    ```
    
    You can also find the Username in the Lab Details pane.
    
4. Click **Next**.
    
5. Copy the **Password** below and paste it into the **Welcome** dialog.
    
    ```apache
    "Password"
    ```
    
    You can also find the Password in the Lab Details pane.
    
6. Click **Next**.
    
    **Important:** You must use the credentials the lab provides you. Do not use your Google Cloud account credentials.
    
    **Note:** Using your own Google Cloud account for this lab may incur extra charges.
    
7. Click through the subsequent pages:
    
    * Accept the terms and conditions.
        
    * Do not add recovery options or two-factor authentication (because this is a temporary account).
        
    * Do not sign up for free trials.
        

After a few moments, the Google Cloud console opens in this tab.

**Note:** To access Google Cloud products and services, click the **Navigation menu** or type the service or product name in the **Search** field.

![Navigation menu icon and Search field](https://cdn.qwiklabs.com/9Fk8NYFp3quE9mF%2FilWF6%2FlXY9OUBi3UWtb2Ne4uXNU%3D align="left")

## Task 1. Created an authorized table

In the first project, you will take on the role of a Data Sharing Partner creating and sharing a dataset using an authorized table.

### Create the Customer Authorized Table

1. From the lab pane. open the **Data Sharing Partner Project Console** and log in with the associated credentials.
    
2. From the **Navigation Menu**, go to **BigQuery** &gt; **BigQuery Studio**.
    
3. Run the following query to create a source dataset by selecting the top 10 cities of each state sorted by land area:
    

```sql
SELECT * FROM (
SELECT *, ROW_NUMBER() OVER (PARTITION BY state_code ORDER BY area_land_meters DESC) AS cities_by_area
FROM `bigquery-public-data.geo_us_boundaries.zip_codes`) cities
WHERE cities_by_area <= 10 ORDER BY cities.state_code
LIMIT 1000;
```

4. From the toolbar, click **More** &gt; **Query Settings**.
    

**Note:** If the **More** option isn't visible, click the three dots on the toolbar to navigate.

5. Select the **Set a destination table for query results** option.
    
6. For the **Dataset** select `qwiklabs-gcp-01-ab504391b5f0.demo_dataset`.
    
7. For **Table ID** type `authorized_table`.
    
8. Leave the rest of the fields as default and click **Save**.
    
9. Click **Run** to run the query again to write the results to the table you specified.
    
10. Verify the `authorized_table` has been created.
    

### Authorize the dataset

1. From the BigQuery Explorer pane, open the **demo\_dataset** and click **\+ Sharing** &gt; **Authorize datasets**.
    
2. Add the **authorized view** that needs to be authorized to share: `qwiklabs-gcp-01-ab504391b5f0.demo_dataset`.
    
3. Click **Add Authorization**.
    
4. Click **Close**.
    

### Grant permissions to the Data Publisher to access the view

1. Under your project, inside of **demo\_dataset**, open `authorized_table`.
    
2. Click **Share**.
    
3. Click on **Add Principal** and add the *Data Publisher* and *Customer* users:
    
    * [`student-01-6b6881c11b27@qwiklabs.net`](mailto:student-01-6b6881c11b27@qwiklabs.net)
        
    * [`student-01-3abc08954018@qwiklabs.net`](mailto:student-01-3abc08954018@qwiklabs.net)
        
4. Select the **BigQuery Data Viewer** role.
    

![add bigquery data viewer principal](https://cdn.qwiklabs.com/DStekZgkLzfZelE44ACntO2xAMTOX%2FhINxYCb0izbo0%3D align="left")

6. Click **Save**.
    

Click **Check my progress** to verify your performed task.

Created an Authorized Table

**Check my progress**

## Task 2. Create an authorized view in the Data Publishing project

In the second project, you will assume the role of a Data Sharing Partner who will share the source dataset in partner project as an authorized view in the Data Publishing project.

1. Close the **Data Sharing Partner Project Console** and from the lab pane open the **Data Publisher Project Console**. Log in with the associated credentials.
    
2. From the **Navigation Menu**, go to **BigQuery** &gt; **BigQuery Studio**.
    
3. Run the following query to select cities in New York state from the authorized view:
    

```sql
SELECT *
FROM `qwiklabs-gcp-01-ab504391b5f0.demo_dataset.authorized_table`
WHERE state_code="NY"
LIMIT 1000
```

4. On the query toolbar, select **Save** &gt; **Save View**.
    
5. Click in the **Dataset** field and select `data_publisher_dataset`.
    
6. In the **Table** field, type `authorized_view`.
    
7. Click **Save**. You should now be able to see the dataset and table, as well as query it.
    

### Assign IAM permissions to the Data Publisher view

1. From the BigQuery Explorer pane, open the **data\_publisher\_dataset** and click **\+ Sharing** &gt; **Authorize Views**.
    
2. Add the **authorized view** that needs to be authorized to share: [`qwiklabs-gcp-01-92a5cac8148e.data`](http://qwiklabs-gcp-01-92a5cac8148e.data)`_publisher_dataset.authorized_view`.
    
3. Click **Add Authorization**.
    
4. Click **Close**.
    

### Grant permissions to the customer to access the view

1. Under your project, inside of **data\_publisher\_dataset**, open `authorized_view`.
    
2. Click **Share**.
    
3. Click on **Add Principal** and add the *Customer* user:
    
    * [`student-01-3abc08954018@qwiklabs.net`](mailto:student-01-3abc08954018@qwiklabs.net)
        
4. Select the **BigQuery Data Viewer** role.
    

![add bigquery data viewer principal](https://cdn.qwiklabs.com/b3FYUsWh5Rzs1jP8D8FYQpGS7y5WgVEzl0%2BLVpFhuFY%3D align="left")

6. Click **Save**.
    

Click **Check my progress** to verify your performed task.

Create an authorized view in the Data Publishing project

**Check my progress**

## Task 3. Access the authorized view as a Data Twin

In the third project, the student will assume the role of a customer who will access the authorized view into their project as a Data Twin and join the data with their solution dataset to create enriched datasets.

1. Close the **Data Publisher Console** and from the lab pane open the **Customer (Data Twin) Project Console**. Log in with the associated credentials.
    
2. From the **Navigation Menu**, go to **BigQuery** &gt; **BigQuery Studio**.
    
3. Execute the following query to access data from the Data Sharing Partner Data publishing project and join the Customerâ€™s data and partner's view to create new insights.
    

```sql
SELECT cities.zip_code, cities.city, cities.state_code, customers.last_name, customers.first_name
FROM `qwiklabs-gcp-00-cae668ff8d46.customer_dataset.customer_info` as customers
JOIN `qwiklabs-gcp-01-92a5cac8148e.data_publisher_dataset.authorized_view` as cities
ON cities.state_code = customers.state;
```

Your results should resemble the following:

![customer query](https://cdn.qwiklabs.com/tYBtsY050EkG9Wiab4NjmYdtZrNiqH%2F0quHZau1CVk8%3D align="left")

4. On the query toolbar, select **Save** &gt; **Save View**.
    
5. Click in the **Dataset** field and select `customer_dataset`.
    
6. In the **Table** field, type `customer_table`.
    
7. Click **Save**. You should now be able to see the dataset and table, as well as query it.
    

Click **Check my progress** to verify your performed task.

Access the authorized view as a Data Twin

**Check my progress**

## Task 4. Confirm functionality of the Customer (Data Twin)

To confirm the functionality of the Data Twin, you will insert a new row in the Data Sharing Partner Project and test the functionality inside of the customer project.

1. Close the **Customer (Data Twin) Project Console** and from the lab pane open the **Data Sharing Partner Project Console**. Log in with the associated credentials.
    
2. From the **Navigation Menu**, go to **BigQuery** &gt; **BigQuery Studio**.
    
3. Run the following query to insert a new row in the Data Sharing Partner dataset:
    

```sql
INSERT INTO
 `qwiklabs-gcp-01-ab504391b5f0.demo_dataset.authorized_table` (zip_code,
   city,
   county,
   state_fips_code,
   state_code,
   state_name,
   fips_class_code,
   mtfcc_feature_class_code,
   functional_status,
   area_land_meters,
   area_water_meters,
   cities_by_area)
VALUES
 ("11012", "New City", "New County", "02", "NY", "New York", "B5", "G6350", "S", 123632007174.0, 544474039.0, 10)
```

You should see the following output

```apache
This statement added 1 row to authorized_table.
```

4. Close the **Data Sharing Partner Project Console** and from the lab pane open the **Customer (Data Twin) Project Console**. Log in with the associated credentials.
    
5. Finally, query the view in Customer (Data Twin) project to confirm the newly added row is visible.
    

```sql
SELECT cities.zip_code, cities.city, cities.state_code, customers.last_name, customers.first_name
FROM `qwiklabs-gcp-00-cae668ff8d46.customer_dataset.customer_info` as customers
JOIN `qwiklabs-gcp-01-92a5cac8148e.data_publisher_dataset.authorized_view` as cities
ON cities.state_code = customers.state;
```

You results should resemble the following:

![final results updated row](https://cdn.qwiklabs.com/eESuGsswxYc9I1yh9uA1tkThn2Q6YbEXK9jK0sxMruI%3D align="left")

---

## Solution of Lab

### New solution

%[https://youtu.be/2kYyubIn8IE] 

```apache
curl -LO raw.githubusercontent.com/Techcps/Google-Cloud-Skills-Boost/master/Consuming%20Customer%20Specific%20Datasets%20from%20Data%20Sharing%20Partners%20using%20BigQuery/techcps1.sh
sudo chmod +x techcps1.sh
./techcps1.sh
```

```apache
curl -LO raw.githubusercontent.com/Techcps/Google-Cloud-Skills-Boost/master/Consuming%20Customer%20Specific%20Datasets%20from%20Data%20Sharing%20Partners%20using%20BigQuery/techcps2.sh
sudo chmod +x techcps2.sh
./techcps2.sh
```

---

### **Old solution**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1752482664101/c8173540-f6ef-41da-8313-d72547e3dfcc.png align="center")

**âš™ï¸ Execute the Following Commands in Cloud Shell (Data Sharing Partner Project Console)**

```apache
curl -LO https://raw.githubusercontent.com/QUICK-GCP-LAB/2-Minutes-Labs-Solutions/refs/heads/main/Consuming%20Customer%20Specific%20Datasets%20from%20Data%20Sharing%20Partners%20using%20BigQuery/gsp1043-1.sh
sudo chmod +x *.sh
./*.sh
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1752482615458/92748ef5-f96f-4b10-ad2e-8137ce6e3dd8.png align="center")

**âš™ï¸ Execute the Following Commands in Cloud Shell (Data Publisher Project Console)**

```apache
curl -LO https://raw.githubusercontent.com/QUICK-GCP-LAB/2-Minutes-Labs-Solutions/refs/heads/main/Consuming%20Customer%20Specific%20Datasets%20from%20Data%20Sharing%20Partners%20using%20BigQuery/gsp1043-2.sh
sudo chmod +x *.sh
./*.sh
```

**âš™ï¸ Execute the Following Commands in Cloud Shell (Customer (Data Twin) Project Console)**

```apache
curl -LO https://raw.githubusercontent.com/QUICK-GCP-LAB/2-Minutes-Labs-Solutions/refs/heads/main/Consuming%20Customer%20Specific%20Datasets%20from%20Data%20Sharing%20Partners%20using%20BigQuery/gsp1043-3.sh
sudo chmod +x *.sh
./*.sh
```

**ðŸŽ‰ Woohoo! You Did It! ðŸŽ‰**