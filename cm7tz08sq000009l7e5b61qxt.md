---
title: "Create and Manage Cloud SQL for PostgreSQL Instances: Challenge Lab - GSP355"
seoTitle: "Create and Manage Cloud SQL for PostgreSQL Instances: Challenge Lab - "
seoDescription: "In a challenge lab you’re given a scenario and a set of tasks. Instead of following step-by-step instructions, you will use the skills learned from the labs"
datePublished: Tue Mar 04 2025 04:10:03 GMT+0000 (Coordinated Universal Time)
cuid: cm7tz08sq000009l7e5b61qxt
slug: create-and-manage-cloud-sql-for-postgresql-instances-challenge-lab-gsp355
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1741061279859/f5242fa8-743c-4272-b0a6-a7225a030034.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1741061390322/43a9a2c5-dce5-493c-96fa-cedb0a12f314.png
tags: create-and-manage-cloud-sql-for-postgresql-instances-challenge-lab-gsp355, gsp355, create-and-manage-cloud-sql-for-postgresql-instances-challenge-lab

---

## **Overview**

In a challenge lab you’re given a scenario and a set of tasks. Instead of following step-by-step instructions, you will use the skills learned from the labs in the course to figure out how to complete the tasks on your own! An automated scoring system (shown on this page) will provide feedback on whether you have completed your tasks correctly.

When you take a challenge lab, you will not be taught new Google Cloud concepts. You are expected to extend your learned skills, like changing default values and reading and researching error messages to fix your own mistakes.

To score 100% you must successfully complete all tasks within the time period!

This lab is recommended for students who have enrolled in the [Create and Manage Cloud SQL for PostgreSQL Instances](https://www.cloudskillsboost.google/course_templates/652) skill badge. Are you ready for the challenge?

### Topics tested

* Migrate a stand-alone PostgreSQL database to Cloud SQL for PostgreSQL using Database Migration Services.
    
* Promote the Cloud SQL database to a stand-alone instance for reading and writing.
    
* Secure the database using IAM DB Authentication.
    
* Perform a point-in-time recovery on the database.
    

## **Setup and requirements**

### Before you click the Start Lab button

Read these instructions. Labs are timed and you cannot pause them. The timer, which starts when you click **Start Lab**, shows how long Google Cloud resources are made available to you.

This hands-on lab lets you do the lab activities in a real cloud environment, not in a simulation or demo environment. It does so by giving you new, temporary credentials you use to sign in and access Google Cloud for the duration of the lab.

To complete this lab, you need:

* Access to a standard internet browser (Chrome browser recommended).
    

**Note:** Use an Incognito (recommended) or private browser window to run this lab. This prevents conflicts between your personal account and the student account, which may cause extra charges incurred to your personal account.

* Time to complete the lab—remember, once you start, you cannot pause a lab.
    

**Note:** Use only the student account for this lab. If you use a different Google Cloud account, you may incur charges to that account.

### How to start your lab and sign in to the Google Cloud console

1. Click the **Start Lab** button. If you need to pay for the lab, a dialog opens for you to select your payment method. On the left is the Lab Details pane with the following:
    
    * The Open Google Cloud console button
        
    * Time remaining
        
    * The temporary credentials that you must use for this lab
        
    * Other information, if needed, to step through this lab
        
2. Click **Open Google Cloud console** (or right-click and select **Open Link in Incognito Window** if you are running the Chrome browser).
    
    The lab spins up resources, and then opens another tab that shows the Sign in page.
    
    ***Tip:*** Arrange the tabs in separate windows, side-by-side.
    
    **Note:** If you see the **Choose an account** dialog, click **Use Another Account**.
    
3. If necessary, copy the **Username** below and paste it into the **Sign in** dialog.
    
    ```apache
    student-00-406e32055a40@qwiklabs.net
    ```
    
    You can also find the Username in the Lab Details pane.
    
4. Click **Next**.
    
5. Copy the **Password** below and paste it into the **Welcome** dialog.
    
    ```apache
    w456lHZylNSq
    ```
    
    You can also find the Password in the Lab Details pane.
    
6. Click **Next**.
    
    **Important:** You must use the credentials the lab provides you. Do not use your Google Cloud account credentials.
    
    **Note:** Using your own Google Cloud account for this lab may incur extra charges.
    
7. Click through the subsequent pages:
    
    * Accept the terms and conditions.
        
    * Do not add recovery options or two-factor authentication (because this is a temporary account).
        
    * Do not sign up for free trials.
        

After a few moments, the Google Cloud console opens in this tab.

**Note:** To access Google Cloud products and services, click the **Navigation menu** or type the service or product name in the **Search** field.

![Navigation menu icon and Search field](https://cdn.qwiklabs.com/9Fk8NYFp3quE9mF%2FilWF6%2FlXY9OUBi3UWtb2Ne4uXNU%3D align="left")

### Challenge scenario

Your employer has a stand-alone PostgreSQL database on a Compute Instance VM. You have been tasked with migrating the database to a Cloud SQL for PostgreSQL instance using Database Migration Services and VPC Peering. You are then required to configure and test Cloud SQL IAM Database Authentication on the migrated instance, and finally enable backups and point-in-time recovery so that the database is protected. You are required to confirm that point-in-time recovery works by using it to create a clone of the database to a particular timestamp.

## **Task 1. Migrate a stand-alone PostgreSQL database to a Cloud SQL for PostgreSQL instance**

In this task you must migrate the stand-alone PostgreSQL `orders` database running on the `postgres-vm` virtual machine to a Cloud SQL for PostgreSQL instance using a Database Migration Services continuous migration job and VPC Peering connectivity.

### Prepare the stand-alone PostgreSQL database for migration

In this sub-task you must prepare the stand-alone PostgreSQL database so that it satisfies the requirements for migration by Database Migration Services.

To complete this sub-task you must complete the following steps:

1. Enable the Google Cloud APIs required for Database Migration Services.
    

Database Migration Services require the **Database Migration API** and the **Service Networking API** to be enabled in order to function. You must enable these APIs for your project.

2. Upgrade the target databases on the `postgres-vm` virtual machine with the `pglogical` database extension.
    
3. You must install and configure the **pglogical** database extension on the stand-alone PostgreSQL database on the `postgres-vm` Compute Instance VM. The pglogical database extension package that you must install is named `postgresql-13-pglogical`.
    
4. To complete the configuration of the **pglogical** database extension you must edit the PostgreSQL configuration file `/etc/postgresql/13/main/postgresql.conf` to enable the **pglogical** database extension and you must edit the `/etc/postgresql/13/main/pg_hba.conf` to allow access from all hosts.
    
5. Create a dedicated user for database migration on the stand-alone database.
    
6. The new user that you create on the stand-alone PostgreSQL installation on the `postgres-vm` virtual machine must be configured using the following user name and password:
    

* **Migration user name** : `import_admin`
    
* **Migration user password** : `DMS_1s_cool!`
    

7. Grant that user the required privileges and permissions for databases to be migrated.
    

Database Migration Services require that the migration user has privileges to specific schemata and relations of the target databases for migration, in this case that is the `orders` database.

The Database Migration Service requires all tables to be migrated to have a primary key.

8. You must make sure that all of the tables in the `orders` database have a primary key set before you start the migration.
    

* `distribution_centers`
    
* `inventory_items`
    
* `order_items`
    
* `products`
    
* `users`
    

**Note:** The detailed pre-requisites for migrating a stand-alone PostgreSQL database to Cloud SQL for PostgreSQL are provided in the suggestion links in the Cloud Console GUI for Database Migration Services.

Should you need some help on the detailed steps you must take, you may refer to that documentation, or you can look at the detailed steps in the migration lab that is part of this course.

Prepare a stand-alone PostgreSQL database for migration to Cloud SQL for PostgreSQL.

Check my progress

### Migrate the stand-alone PostgreSQL database to a Cloud SQL for PostgreSQL instance

In this sub-task you must perform the migration using Database Migration Services.

To complete this sub-task you must complete the following steps:

1. Create a new Database Migration Service connection profile for the stand-alone PostgreSQL database, using the credentials of the `import_admin` migration user you created earlier.
    

* **Username** : `import_admin`
    
* **Password** : `DMS_1s_cool!`
    
* **Region** must be set to `us-east1`
    

2. You must configure the connection profile using the internal ip-address of the source compute instance.
    
3. Create a new continuous Database Migration Service job.
    

As part of the migration job configuration, make sure that you specify the following properties for the destination Cloud SQL instance:

![The completed Migration job type field; Continuous.](https://cdn.qwiklabs.com/FNtaNG5yDcVRz%2Bd3WAIoD4q%2FFt0Arb%2BEp0uMX1nVrCg%3D align="left")

* The **Destination Instance ID** must be set to `postgres24-aipat`
    
* The **Password** for the migrated instance must be set to `supersecret!`
    
* **Database version** must be set to **Cloud SQL for PostgreSQL 13**
    
* **Region** must be set to `us-east1`
    
* For **Connections** both **Public IP** and **Private IP** must be set.
    
* For Private IP use an automatically allocated IP range.
    
* Select **Enterprise** Cloud SQL edition.
    
* Select a dedicated core machine shapes with 2 vCPU and 8GB of memory.
    

**Note:** You will need to wait while the private ip-address is allocated. Once the Create & Continue appears, you can proceed.

4. For the **Connectivity Method**, you must use **VPC peering** with the **default** VPC network.
    
5. Test and then start the continuous migration job.
    

If you do not correctly prepare the source PostgreSQL environment, the migration might fail completely, or it might fail to migrate some individual tables. If some tables are missing, even though the migration appears to be working otherwise, check that you have correctly configured all of the source database tables.

Migrate a stand-alone PostgreSQL database to a Cloud SQL for PostgreSQL instance.

Check my progress

## **Task 2. Promote a Cloud SQL to be a stand-alone instance for reading and writing data**

* In this task, you must complete the migration by promoting the Cloud SQL for PostgreSQL instance to a stand-alone instance.
    
* When the promotion is complete, the status of the job updates to Completed.
    
    Promote a Cloud SQL Migration Replica to a stand-alone instance.
    
    Check my progress
    

## **Task 3. Implement Cloud SQL for PostgreSQL IAM database authentication**

In this task you must configure the newly migrated Cloud SQL for PostgreSQL instance to support Cloud IAM users and IAM database authentication. You are also required to patch the Cloud SQL for PostgreSQL instance, to add the public ip-address of the `postgres-vm` virtual machine to the list of networks that are allowed to connect to the instance.

To complete this task you must complete the following steps:

1. Patch the `postgres24-aipat` Cloud SQL instance to allow connections from the public ip-address of the `postgres-vm` virtual machine.
    
    * In the `postgres24-aipat` Cloud SQL instance, go to **connections &gt; Networking**.
        
    * Under the Public IP, click on **ADD A NETWORK**. For the network, use the external IP of the `postgres-vm` virtual machine.
        
2. In the `postgres24-aipat` Cloud SQL instance, create a Cloud SQL IAM user using the lab student ID, `student-00-406e32055a40@qwiklabs.net`, as the principal account name.
    
    * Click **Users &gt; Add user account**, then select **Cloud IAM**.
        
3. Grant `SELECT` permission to the Cloud IAM user for the `order_items` table.
    
    * In the `postgres24-aipat` Cloud SQL instance, go to **Overview**. Under **Connect to this instance**, click on **Open Cloud Shell**.
        
    * For the password enter `supersecret!`. Then connect to the orders database using `\c orders;` command.
        
    * Again for the password enter `supersecret!`.
        
    * Use the following command to grant SELECT permission. Replace the **Table\_Name** and **Qwiklabs\_User\_Account\_Name** variables with the correct values.
        
        ```sql
        GRANT SELECT ON Table_Name TO "Qwiklabs_User_Account_Name";
        ```
        
4. Run the following query as the `student-00-406e32055a40@qwiklabs.net` user in the migrated database to confirm that the `student-00-406e32055a40@qwiklabs.net` can select data from the `order_items` table.
    
5. `SELECT COUNT(*) FROM order_items;`
    

Secure a Cloud SQL for PostgreSQL database table using Cloud IAM database authentication.

Check my progress

## **Task 4. Configure and test point-in-time recovery**

In this task you must configure point-in-time recovery on a Cloud SQL for PostgreSQL instance and then test it by using point-in-time recovery to create a cloned instance at a point in time that rolls back some changes.

To complete this task you must complete the following steps:

1. Enable backups on the Cloud SQL for PostgreSQL instance.
    
    * In the `postgres24-aipat` Cloud SQL instance, go to **Overview**. Click on **edit** &gt; **Data Protection**.
        
    * Enable point-in-time recovery and set the number of retained transaction log days to `6`.
        
2. Make a note of the timestamp for the point-in-time you wish to restore to using the following command.
    
    ```apache
    date -u --rfc-3339=ns | sed -r 's/ /T/; s/\.([0-9]{3}).*/\.\1Z/'
    ```
    
3. Make some changes to the database after this timestamp.
    
    * In the `postgres24-aipat` Cloud SQL instance, go to **Overview**. Under **Connect to this instance**, click on **Open Cloud Shell**.
        
    * For the password enter `supersecret!`. Then connect to the orders database using `\c orders;` command.
        
    * Again for the password enter `supersecret!`.
        
    * You must add a row of data to the `orders.distribution_centers` table.
        
4. Use point-in-time recovery to create a clone that replicates the instance state at your chosen timestamp.
    
    * Use the following command to clone the instance by replacing the **CLOUDSQL\_INSTANCE**, **NEW\_INSTANCE\_NAME** and **TIME\_STAMP** variables with the correct values.
        
        ```apache
        gcloud sql instances clone $CLOUDSQL_INSTANCE $NEW_INSTANCE_NAME \
         --point-in-time $TIME_STAMP
        ```
        
    * For the **Cloned instance name** you must use the name `postgres-orders-pitr`.
        

The new instance will not be used, but do not discard it, as it will be required to confirm that you have correctly completed the lab.

**Note:** You must specify the point-in-time recovery timestamp in UTC time, specified in RFC 3339 format 'yyyy-MM-ddThh:mm:ss.mmmZ'.

Enable and test point-in-time recovery.

---

## Solution of Lab

%[https://www.youtube.com/watch?v=KrFAmq3CBz8&ab_channel=QuickLab%E2%98%81%EF%B8%8F] 

### Enable the following Google APIs:

* [**Database Migration API**](https://console.cloud.google.com/marketplace/product/google/datamigration.googleapis.com?q=search&referrer=search&project=)
    
* [**Service Networking API**](https://console.cloud.google.com/marketplace/product/google/servicenetworking.googleapis.com?q=search&referrer=search&project=)
    

### Compute Engine &gt; VM instances &gt; Connect the SSH of postgresql-vm

* **install the pglogical database extension and jquery**
    

```apache
sudo apt install postgresql-13-pglogical
```

* **Download and apply some additions to the PostgreSQL configuration files (to enable pglogical extension)**
    

```apache
sudo su - postgres -c "gsutil cp gs://cloud-training/gsp918/pg_hba_append.conf ."
sudo su - postgres -c "gsutil cp gs://cloud-training/gsp918/postgresql_append.conf ."
sudo su - postgres -c "cat pg_hba_append.conf >> /etc/postgresql/13/main/pg_hba.conf"
sudo su - postgres -c "cat postgresql_append.conf >> /etc/postgresql/13/main/postgresql.conf"
sudo systemctl restart postgresql@13-main
```

* **Apply required privileges to postgres and orders databases**
    

```apache
sudo su - postgres
```

```apache
psql
```

```apache
\c postgres;
```

```apache
CREATE EXTENSION pglogical;
```

```apache
\c orders;
```

```apache
CREATE EXTENSION pglogical;
```