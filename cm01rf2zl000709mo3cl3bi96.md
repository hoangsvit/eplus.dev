---
title: "Importing Data to a Firestore Database - GSP642"
seoTitle: "Importing Data to a Firestore Database - GSP642"
seoDescription: "Twelve years ago, Lily started the Pet Theory chain of veterinary clinics. The Pet Theory chain has expanded rapidly over the last few years. However, their"
datePublished: Tue Aug 20 2024 01:42:09 GMT+0000 (Coordinated Universal Time)
cuid: cm01rf2zl000709mo3cl3bi96
slug: importing-data-to-a-firestore-database-gsp642
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1724117904064/29aadebd-560c-4002-b3fb-3ae97f56e8ee.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1724118120327/a0c271d2-4c9f-441b-baee-828bbce8e1f1.png
tags: importing-data-to-a-firestore-database-gsp642

---

## **Overview**

Twelve years ago, Lily started the Pet Theory chain of veterinary clinics. The Pet Theory chain has expanded rapidly over the last few years. However, their old appointment scheduling system is not able to handle the increased load, so Lily is asking you to build a cloud-based system that scales better than the legacy solution.

Pet Theory's Ops team is a single person, Patrick, so they need a solution that doesn't require lots of ongoing maintenance. The team has decided to go with serverless technology.

Ruby has been hired as a consultant to help Pet Theory make the transition to serverless. After comparing serverless database options, the team decides to go with [Cloud Firestore](https://firebase.google.com/docs/firestore). Since Firestore is serverless, capacity doesn't have to be provisioned ahead of time which means that there is no risk of running into storage or operations limits. Firestore keeps your data in sync across client apps through real-time listeners and offers offline support for mobile and web, so a responsive app can be built that works regardless of network latency or Internet connectivity.

In this lab you will help Patrick upload Pet Theory's existing data to a Cloud Firestore database. He will work closely with Ruby to accomplish this.

### Architecture

This diagram gives you an overview of the services you will be using and how they connect to one another:

![Migrating to a Firestore Database architecture diagram](https://cdn.qwiklabs.com/Yfo0T7MHSB8V2VwDmVYNMJQo5bly1%2BtEbv%2FBrpUNbZ8%3D align="left")

## **Objectives**

In this lab, you will learn how to:

* Set up Firestore in Google Cloud.
    
* Write database import code.
    
* Generate a collection of customer data for testing.
    
* Import the test customer data into Firestore.
    

### Prerequisites

This is a **introductory level** lab. This assumes familiarity with the Cloud Console and shell environments. Experience with Firebase will be helpful, but is not required.

You should also be comfortable editing files. You can use your favorite text editor (like `nano`, `vi`, etc.) or you can launch the code editor from Cloud Shell, which can be found in the top ribbon:

![Open Editor button](https://cdn.qwiklabs.com/UqR6a8QkaHUK41NyziQtVya67mqA9ivrzslZSt4sIoo%3D align="left")

Once you're ready, scroll down and follow the steps below to set up your lab environment.

## **Setup and requirements**

### Before you click the Start Lab button

Read these instructions. Labs are timed and you cannot pause them. The timer, which starts when you click **Start Lab**, shows how long Google Cloud resources will be made available to you.

This hands-on lab lets you do the lab activities yourself in a real cloud environment, not in a simulation or demo environment. It does so by giving you new, temporary credentials that you use to sign in and access Google Cloud for the duration of the lab.

To complete this lab, you need:

* Access to a standard internet browser (Chrome browser recommended).
    

**Note:** Use an Incognito or private browser window to run this lab. This prevents any conflicts between your personal account and the Student account, which may cause extra charges incurred to your personal account.

* Time to complete the lab---remember, once you start, you cannot pause a lab.
    

**Note:** If you already have your own personal Google Cloud account or project, do not use it for this lab to avoid extra charges to your account.

### How to start your lab and sign in to the Google Cloud console

1. Click the **Start Lab** button. If you need to pay for the lab, a pop-up opens for you to select your payment method. On the left is the **Lab Details** panel with the following:
    
    * The **Open Google Cloud console** button
        
    * Time remaining
        
    * The temporary credentials that you must use for this lab
        
    * Other information, if needed, to step through this lab
        
2. Click **Open Google Cloud console** (or right-click and select **Open Link in Incognito Window** if you are running the Chrome browser).
    
    The lab spins up resources, and then opens another tab that shows the **Sign in** page.
    
    ***Tip:*** Arrange the tabs in separate windows, side-by-side.
    
    **Note:** If you see the **Choose an account** dialog, click **Use Another Account**.
    
3. If necessary, copy the **Username** below and paste it into the **Sign in** dialog.
    
    ```apache
    student-04-0ee72c84c098@qwiklabs.net
    ```
    
    You can also find the **Username** in the **Lab Details** panel.
    
4. Click **Next**.
    
5. Copy the **Password** below and paste it into the **Welcome** dialog.
    
    ```apache
    tMy03AHhhKsz
    ```
    
    You can also find the **Password** in the **Lab Details** panel.
    
6. Click **Next**.
    
    **Important:** You must use the credentials the lab provides you. Do not use your Google Cloud account credentials.
    
    **Note:** Using your own Google Cloud account for this lab may incur extra charges.
    
7. Click through the subsequent pages:
    
    * Accept the terms and conditions.
        
    * Do not add recovery options or two-factor authentication (because this is a temporary account).
        
    * Do not sign up for free trials.
        

After a few moments, the Google Cloud console opens in this tab.

**Note:** To view a menu with a list of Google Cloud products and services, click the **Navigation menu** at the top-left.

![Navigation menu icon](https://cdn.qwiklabs.com/nUxFb6oRFr435O3t6V7WYJAjeDFcrFb16G9wHWp5BzU%3D align="left")

### Activate Cloud Shell

Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud. Cloud Shell provides command-line access to your Google Cloud resources.

1. Click **Activate Cloud Shell**
    
    ![Activate Cloud Shell icon](https://cdn.qwiklabs.com/ep8HmqYGdD%2FkUncAAYpV47OYoHwC8%2Bg0WK%2F8sidHquE%3D align="left")
    
    at the top of the Google Cloud console.
    

When you are connected, you are already authenticated, and the project is set to your **Project\_ID**, `qwiklabs-gcp-00-c4bf739fa351`. The output contains a line that declares the **Project\_ID** for this session:

```apache
Your Cloud Platform project in this session is set to qwiklabs-gcp-00-c4bf739fa351
```

`gcloud` is the command-line tool for Google Cloud. It comes pre-installed on Cloud Shell and supports tab-completion.

2. (Optional) You can list the active account name with this command:
    

```apache
gcloud auth list
```

3. Click **Authorize**.
    

**Output:**

```apache
ACTIVE: *
ACCOUNT: student-04-0ee72c84c098@qwiklabs.net

To set the active account, run:
    $ gcloud config set account `ACCOUNT`
```

4. (Optional) You can list the project ID with this command:
    

```apache
gcloud config list project
```

**Output:**

```apache
[core]
project = qwiklabs-gcp-00-c4bf739fa351
```

**Note:** For full documentation of `gcloud`, in Google Cloud, refer to [the gcloud CLI overview guide](https://cloud.google.com/sdk/gcloud).

## **Task 1. Set up Firestore in Google Cloud**

Patrick's task is to upload Pet Theory's existing data to a Cloud Firestore database. He will work closely with Ruby to accomplish this goal. Ruby receives a message from Patrick in IT...

| *Patrick, IT Administrator* | Hi Ruby, |
| --- | --- |
| *Ruby, Software Consultant* | Hey Patrick, |

Help Patrick set up a Firestore database through the Cloud Console.

1. In the Cloud Console, go to the **Navigation menu** and select **Firestore**.
    
2. Click **+Create Database**.
    
3. Select the **Native mode** option and click **Continue**.
    

**Note:** Both modes are high performing with strong consistency, but they look different and are optimized for different use cases.

* *Native Mode* is good for letting lots of users access the same data at the same time (plus, it has features like real-time updates and direct connection between your database and a web/mobile client
    
* *Datastore Mode* puts an emphasis on high throughput (lots of reads and writes).
    

4. In the **Region** dropdown, select `us-west1` region and then click **Create Database**.
    

On completion of the task, Ruby emails Patrick...

| *Ruby, Software Consultant* | Hey Patrick, |
| --- | --- |
| *Patrick, IT Administrator* | Hey Ruby, |

## **Task 2. Write database import code**

The new Cloud Firestore database is in place, but it's empty. The customer data for Pet Theory still only exists in the old database.

Patrick sends a message to Ruby...

| *Patrick, IT Administrator* | Hi Ruby, |
| --- | --- |
| *Ruby, Software Consultant* | Hey Patrick, |

As Patrick said, the customer data will be available in a CSV file. Help Patrick create an app that reads customer records from a CSV file and writes them to Firestore. Since Patrick is familiar with Javascript, build this application with the Node.js JavaScript runtime.

1. In Cloud Shell, run the following command to clone the Pet Theory repository:
    

```apache
git clone https://github.com/rosera/pet-theory
```

2. Use the Cloud Shell Code Editor (or your preferred editor) to edit your files. From the top ribbon of your Cloud Shell session, click **Open Editor**, it will open a new tab. If prompted, click **Open in a new window** to launch the code editor:
    

![Open Editor button](https://cdn.qwiklabs.com/UqR6a8QkaHUK41NyziQtVya67mqA9ivrzslZSt4sIoo%3D align="left")

3. Then change your current working directory to `lab01`:
    

```apache
cd pet-theory/lab01
```

In the directory you can see Patrick's `package.json`. This file lists the packages that your Node.js project depends on and makes your build reproducible, and therefore easier to share with others.

An example `package.json` is shown below:

```apache
{
	"name": "lab01",
	"version": "1.0.0",
	"description": "This is lab01 of the Pet Theory labs",
	"main": "index.js",
	"scripts": {
		"test": "echo \"Error: no test specified\" && exit 1"
	},
	"keywords": [],
	"author": "Patrick - IT",
	"license": "MIT",
	"dependencies": {
		"csv-parse": "^5.5.3"
	}
}
```

Now that Patrick has his source code imported, he gets in touch with Ruby to see what packages he needs to make the migration work.

| *Patrick, IT Administrator* | Hi Ruby, |
| --- | --- |
| *Ruby, Software Consultant* | Hi Patrick, |

To allow Patrick's code to write to the Firestore database, you need to install some additional peer dependencies.

4. Run the following command to do so:
    

```apache
npm install @google-cloud/firestore
```

5. To enable the app to write logs to Cloud Logging, install an additional module:
    

```apache
npm install @google-cloud/logging
```

After successful completion of the command, the `package.json` will be automatically updated to include the new peer dependencies, and will look like this.

```apache
...

"dependencies": {
  "@google-cloud/firestore": "^7.3.0",
  "@google-cloud/logging": "^11.0.0",
  "csv-parse": "^5.5.3"
}
```

Now it's time to take a look at the script that reads the CSV file of customers and writes one record in Firestore for each line in the CSV file. Patrick's original application is shown below:

```apache
const csv = require('csv-parse');
const fs  = require('fs');

function writeToDatabase(records) {
  records.forEach((record, i) => {
    console.log(`ID: ${record.id} Email: ${record.email} Name: ${record.name} Phone: ${record.phone}`);
  });
  return ;
}

async function importCsv(csvFilename) {
  const parser = csv.parse({ columns: true, delimiter: ',' }, async function (err, records) {
    if (e) {
      console.error('Error parsing CSV:', e);
      return;
    }
    try {
      console.log(`Call write to Firestore`);
      await writeToDatabase(records);
      console.log(`Wrote ${records.length} records`);
    } catch (e) {
      console.error(e);
      process.exit(1);
    }
  });

  await fs.createReadStream(csvFilename).pipe(parser);
}

if (process.argv.length < 3) {
  console.error('Please include a path to a csv file');
  process.exit(1);
}

importCsv(process.argv[2]).catch(e => console.error(e));
```

It takes the output from the input CSV file and imports it into the legacy database. Next, update this code to write to Firestore.

6. Open the file `pet-theory/lab01/importTestData.js`.
    

To reference the Firestore API via the application, you need to add the peer dependency to the existing codebase.

7. Add the following Firestore dependency on line 3 of the file:
    

```apache
const { Firestore } = require("@google-cloud/firestore");
```

Ensure that the top of the file looks like this:

```apache
const csv = require('csv-parse');
const fs  = require('fs');
const { Firestore } = require("@google-cloud/firestore"); // Add this
```

Integrating with the Firestore database can be achieved with a couple of lines of code. Ruby has shared some template code with you and Patrick for exactly that purpose.

8. Add the following code underneath line 34, or after the `if (process.argv.length < 3)` conditional:
    

```javascript
async function writeToFirestore(records) {
  const db = new Firestore({  
    // projectId: projectId
  });
  const batch = db.batch()

  records.forEach((record)=>{
    console.log(`Write: ${record}`)
    const docRef = db.collection("customers").doc(record.email);
    batch.set(docRef, record, { merge: true })
  })

  batch.commit()
    .then(() => {
       console.log('Batch executed')
    })
    .catch(err => {
       console.log(`Batch error: ${err}`)
    })
  return
}
```

The above code snippet declares a new database object, which references the database created earlier in the lab. The function uses a batch process in which each record is processed in turn and given a document reference based on the identifier added. At the end of the function, the batch content is committed (written) to the database.

9. Update the `importCsv` function to add the function call to **writeToFirestore** and remove the call to **writeToDatabase**. It should look like this:
    

```javascript
async function importCsv(csvFilename) {
  const parser = csv.parse({ columns: true, delimiter: ',' }, async function (err, records) {
    if (err) {
      console.error('Error parsing CSV:', err);
      return;
    }
    try {
      console.log(`Call write to Firestore`);
      await writeToFirestore(records);
      // await writeToDatabase(records);
      console.log(`Wrote ${records.length} records`);
    } catch (e) {
      console.error(e);
      process.exit(1);
    }
  });

  await fs.createReadStream(csvFilename).pipe(parser);
}
```

10. Add logging for the application. To reference the Logging API via the application, add the peer dependency to the existing codebase. Add the following line just below the other require statements at the top of the file:
    

```javascript
const { Logging } = require('@google-cloud/logging');
```

Ensure that the top of the file looks like this:

```javascript
const csv = require('csv-parse');
const fs  = require('fs');
const { Firestore } = require("@google-cloud/firestore");
const { Logging } = require('@google-cloud/logging');
```

11. Add a few constant variables and initialize the Logging client. Add those just below the above lines in the file (~line 5), like this:
    

```javascript
const logName = "pet-theory-logs-importTestData";

// Creates a Logging client
const logging = new Logging();
const log = logging.log(logName);

const resource = {
  type: "global",
};
```

12. Add code to write the logs in `importCsv` function just below the line "console.log(`Wrote ${records.length} records`);" which should look like this:
    

```javascript
// A text log entry
success_message = `Success: importTestData - Wrote ${records.length} records`;
const entry = log.entry(
	{ resource: resource },
	{ message: `${success_message}` }
);
log.write([entry]);
```

After these updates, your `importCsv` function code block should look like the following:

```javascript
async function importCsv(csvFilename) {
  const parser = csv.parse({ columns: true, delimiter: ',' }, async function (err, records) {
    if (err) {
      console.error('Error parsing CSV:', err);
      return;
    }
    try {
      console.log(`Call write to Firestore`);
      await writeToFirestore(records);
      // await writeToDatabase(records);
      console.log(`Wrote ${records.length} records`);
      // A text log entry
      success_message = `Success: importTestData - Wrote ${records.length} records`;
      const entry = log.entry(
	     { resource: resource },
	     { message: `${success_message}` }
      );
      log.write([entry]);
    } catch (e) {
      console.error(e);
      process.exit(1);
    }
  });

  await fs.createReadStream(csvFilename).pipe(parser);
}
```

Now when the application code is running, the Firestore database will be updated with the contents of the CSV file. The function `importCsv` takes a filename and parses the content on a line by line basis. Each line processed is now sent to the Firestore function `writeToFirestore`, where each new record is written to the "customer" database.

**Note:** In a production environment, you will write your own version of the import script.

## **Task 3. Create test data**

Time to import some data! Patrick contacts Ruby about a concern he has about running a test with real customer data...

| *Patrick, IT Administrator* | Hi Ruby, |
| --- | --- |
| *Ruby, Software Consultant* | Hey Patrick, |

Help Patrick get this pseudo-random data generator up and running.

1. First, install the "faker" library, which will be used by the script that generates the fake customer data. Run the following command to update the dependency in `package.json`:
    

```apache
npm install faker@5.5.3
```

2. Now open the file named **createTestData.js** with the code editor and inspect the code. Ensure it looks like the following:
    

```javascript
const fs = require('fs');
const faker = require('faker');

function getRandomCustomerEmail(firstName, lastName) {
  const provider = faker.internet.domainName();
  const email = faker.internet.email(firstName, lastName, provider);
  return email.toLowerCase();
}

async function createTestData(recordCount) {
  const fileName = `customers_${recordCount}.csv`;
  var f = fs.createWriteStream(fileName);
  f.write('id,name,email,phone\n')
  for (let i=0; i<recordCount; i++) {
    const id = faker.datatype.number();
    const firstName = faker.name.firstName();
    const lastName = faker.name.lastName();
    const name = `${firstName} ${lastName}`;
    const email = getRandomCustomerEmail(firstName, lastName);
    const phone = faker.phone.phoneNumber();
    f.write(`${id},${name},${email},${phone}\n`);
  }
  console.log(`Created file ${fileName} containing ${recordCount} records.`);
}

recordCount = parseInt(process.argv[2]);
if (process.argv.length != 3 || recordCount < 1 || isNaN(recordCount)) {
  console.error('Include the number of test data records to create. Example:');
  console.error('    node createTestData.js 100');
  process.exit(1);
}

createTestData(recordCount);
```

3. Add Logging for the codebase. On line 3, add the following reference for the Logging API module from the application code:
    

```javascript
const { Logging } = require("@google-cloud/logging");
```

The top of the file should now look like this:

```javascript
const fs = require("fs");
const faker = require("faker");
const { Logging } = require("@google-cloud/logging"); //add this
```

4. Now, add a few constant variables and initialize the Logging client. Add those just below the `const` statements:
    

```javascript
const logName = "pet-theory-logs-createTestData";

// Creates a Logging client
const logging = new Logging();
const log = logging.log(logName);

const resource = {
	// This example targets the "global" resource for simplicity
	type: "global",
};
```

5. Add code to write the logs in the **createTestData** function just below the line "console.log(`Created file ${fileName} containing ${recordCount} records.`);" which will look like this:
    

```javascript
// A text log entry
const success_message = `Success: createTestData - Created file ${fileName} containing ${recordCount} records.`;
const entry = log.entry(
	{ resource: resource },
	{
		name: `${fileName}`,
		recordCount: `${recordCount}`,
		message: `${success_message}`,
	}
);
log.write([entry]);
```

6. After updating, the `createTestData` function code block should look like this:
    

```javascript
async function createTestData(recordCount) {
  const fileName = `customers_${recordCount}.csv`;
  var f = fs.createWriteStream(fileName);
  f.write('id,name,email,phone\n')
  for (let i=0; i<recordCount; i++) {
    const id = faker.datatype.number();
    const firstName = faker.name.firstName();
    const lastName = faker.name.lastName();
    const name = `${firstName} ${lastName}`;
    const email = getRandomCustomerEmail(firstName, lastName);
    const phone = faker.phone.phoneNumber();
    f.write(`${id},${name},${email},${phone}\n`);
  }
  console.log(`Created file ${fileName} containing ${recordCount} records.`);
  // A text log entry
  const success_message = `Success: createTestData - Created file ${fileName} containing ${recordCount} records.`;
  const entry = log.entry(
	  { resource: resource },
	  {
	  	name: `${fileName}`,
	  	recordCount: `${recordCount}`,
	  	message: `${success_message}`,
	  }
  );
  log.write([entry]);
}
```

7. Run the following command in Cloud Shell to create the file `customers_1000.csv`, which will contain 1000 records of test data:
    

```apache
node createTestData 1000
```

You should receive a similar output:

```apache
Created file customers_1000.csv containing 1000 records.
```

8. Open the file `customers_1000.csv` and verify that the test data has been created.
    

**Test completed task**

Click **Check my progress** to verify your performed task. If you have successfully created a sample test data for the Firestore Database, you will see an assessment score.

Create test data for the Firestore Database

**Check my progress**

## **Task 4. Import the test customer data**

1. To test the import capability, use both the import script and the test data created earlier:
    

```apache
node importTestData customers_1000.csv
```

You should receive a similar output:

```apache
Writing record 500
Writing record 1000
Wrote 1000 records
```

2. If you get an error that resembles the following:
    

```apache
Error: Cannot find module 'csv-parse'
```

Run the following command to add the `csv-parse` package to your environment:

```apache
npm install csv-parse
```

3. Then run the command again. You should receive the following output:
    

```apache
Writing record 500
Writing record 1000
Wrote 1000 records
```

Over the past couple of sections you have seen how Patrick and Ruby have created test data and a script to import data into Firestore. Patrick now feels more confident about loading customer data into the Firestore database.

**Test completed task**

Click **Check my progress** to verify your performed task. If you have successfully imported sample test data into the Firestore Database, you will see an assessment score.

Import test data into the Firestore Database

**Check my progress**

## **Task 5. Inspect the data in Firestore**

With a little help from you and Ruby, Patrick has now successfully migrated the test data to the Firestore database. Open up Firestore and see the results!

1. Return to your Cloud Console tab. In the **Navigation menu** click on **Firestore**. Once there, click on the pencil icon.
    

![Pencil icon](https://cdn.qwiklabs.com/nFl80ik46ax9FXmdDwnDZ7eX5od6KXMp67eV2FPBI3E%3D align="left")

2. Type in `/customers` and press **Enter**.
    
3. Refresh your browser tab and you should see the following list of customers successfully migrated:
    

![customers list](https://cdn.qwiklabs.com/o3CxegxMC1AFD5eosZVGBgJNscW7pGdRELT1M0gk5%2Fc%3D align="left")

---

## Solution of Lab

%[https://www.youtube.com/watch?v=ItmoVLGO5O0] 

```apache
curl -LO raw.githubusercontent.com/quiccklabs/Labs_solutions/master/Importing%20Data%20to%20a%20Firestore%20Database/quicklabgsp642.sh
sudo chmod +x quicklabgsp642.sh
./quicklabgsp642.sh
```