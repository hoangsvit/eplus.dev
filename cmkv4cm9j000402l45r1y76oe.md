---
title: "Text-to-Image Generation with Gemini on Vertex AI (Solution)"
seoTitle: "Text-to-Image Generation with Gemini on Vertex AI (Solution)"
seoDescription: "Learn to use Vertex AI's Gemini model for text-to-image generation in an interactive science tutoring application challenge"
datePublished: Mon Jan 26 2026 12:03:35 GMT+0000 (Coordinated Universal Time)
cuid: cmkv4cm9j000402l45r1y76oe
slug: text-to-image-generation-with-gemini-on-vertex-ai-solution
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1769475559602/be752498-52f5-443f-b519-86d964acea33.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1769475565095/a54bce5e-9743-4f0f-a752-5e27f7b1dbba.png
tags: vertex-ai, text-to-image-generation-with-gemini-on-vertex-ai-solution, text-to-image-generation-with-gemini-on-vertex-ai, text-to-image-generation-with-gemini

---

## Overview

In a challenge lab you’re given a scenario and a set of tasks. Instead of following step-by-step instructions, you will use the skills learned from the labs in the course to figure out how to complete the tasks on your own! An automated scoring system (shown on this page) will provide feedback on whether you have completed your tasks correctly.

When you take a challenge lab, you will not be taught new Google Cloud concepts. You are expected to extend your learned skills, like changing default values and reading and researching error messages to fix your own mistakes.

To score 100% you must successfully complete all tasks within the time period! Are you ready for the challenge?

## Challenge scenario

**Scenario:** You're a developer at Cymbal Solutions which is an educational technology company that provides online tutoring and educational resources. They want to create an interactive science tutoring assistant to help students with questions related to astronomy and other scientific topics. They decide to use Google Cloud’s Vertex AI SDK to build a chat-based solution that can provide informative answers. you need to finish the below tasks:

**Task:** Develop a Python function named `get_chat_response(prompt)`. This function should invoke the `gemini-2.5-flash` model using the supplied `prompt`, which will uses Gemini's ability to understand the text prompt and use it to build an AI Image.

For this challenge, use these questions in the prompt: **"Hello! What are all the colors in a rainbow?"** and **"What is Prism?"**.

**Follow these steps to interact with the Generative AI APIs using Vertex AI Python SDK.**

1. Click **File &gt; New File** to open a new file within the Code Editor.
    
2. Write the Python code to use Google's Vertex AI SDK to interact with the pre-trained Text Generation AI model.
    
3. Create and save the python file.
    
4. Execute the Python file by invoking the below command by replacing the **FILE\_NAME** inside the terminal within the Code Editor pane to view the output.
    

```apache
/usr/bin/python3 /FILE_NAME.py
```

**Note:** You can ignore any warnings related to Python version dependencies.

Click **Check my progress** to verify the objective.

Send the text prompt requests to GenAI and receive the chat responses

---

## Solution of Lab

%[https://youtu.be/i6yyB1XbfiA] 

```apache
curl -LO raw.githubusercontent.com/ePlus-DEV/storage/refs/heads/main/labs/text-to-image-generation-with-gemini-on-vertex-ai-solution/lab.sh
source lab.sh
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1769476362343/80a18eb7-a19b-4112-9d90-4bf17097023c.png align="center")

```apache
python3 main.py
```

**Alternative Solution**

Create a file **main.py**

```python
import vertexai
from vertexai.generative_models import GenerativeModel

PROJECT_ID = "YOUR_PROJECT_ID"
LOCATION = "YOUR_REGION"

vertexai.init(project=PROJECT_ID, location=LOCATION)

def get_chat_response(prompt):
    model = GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    return response.text

if __name__ == "__main__":
    prompts = [
        "Hello! What are all the colors in a rainbow?",
        "What is Prism?"
    ]

    for question in prompts:
        print(f"User: {question}")
        try:
            answer = get_chat_response(question)
            print(f"Model: {answer}\n")
        except Exception as e:
            print(f"Error: {e}")
```